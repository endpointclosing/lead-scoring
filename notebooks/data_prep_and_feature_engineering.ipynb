{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import snowflake.connector\n",
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import datetime as dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.display.max_columns = 1000\n",
    "pd.options.display.max_rows = 100\n",
    "plt.rcParams[\"figure.figsize\"] = (10,8)\n",
    "plt.style.use('seaborn-darkgrid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initiating login request with your identity provider. A browser window should have opened for you to complete the login. If you can't see it, check existing browser windows, or your OS settings. Press CTRL+C to abort and try again...\n"
     ]
    }
   ],
   "source": [
    "con = snowflake.connector.connect(\n",
    "    user=\"tliang@endpointclosing.com\",\n",
    "    account=\"endpoint\",\n",
    "    authenticator=\"externalbrowser\",\n",
    "    role=\"SNOWFLAKE_DATA_ENGINEERING\",\n",
    "    warehouse=\"DATAENGINEERING_WH\"\n",
    ")\n",
    "cur = con.cursor()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### load the datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lead\n",
    "query = \"SELECT * FROM LAKE.SALESFORCE.LEAD\"\n",
    "lead = cur.execute(query).fetch_pandas_all().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "states = {\n",
    "    'AK': 'Alaska',\n",
    "    'AL': 'Alabama',\n",
    "    'AR': 'Arkansas',\n",
    "    'AS': 'American Samoa',#\n",
    "    'AZ': 'Arizona',\n",
    "    'CA': 'California',\n",
    "    'CO': 'Colorado',\n",
    "    'CT': 'Connecticut',\n",
    "    'DC': 'District of Columbia',\n",
    "    'DE': 'Delaware',\n",
    "    'FL': 'Florida',\n",
    "    'GA': 'Georgia',\n",
    "    'GU': 'Guam',#\n",
    "    'HI': 'Hawaii',\n",
    "    'IA': 'Iowa',\n",
    "    'ID': 'Idaho',\n",
    "    'IL': 'Illinois',\n",
    "    'IN': 'Indiana',\n",
    "    'KS': 'Kansas',\n",
    "    'KY': 'Kentucky',\n",
    "    'LA': 'Louisiana',\n",
    "    'MA': 'Massachusetts',\n",
    "    'MD': 'Maryland',\n",
    "    'ME': 'Maine',\n",
    "    'MI': 'Michigan',\n",
    "    'MN': 'Minnesota',\n",
    "    'MO': 'Missouri',\n",
    "    'MP': 'Northern Mariana Islands',#\n",
    "    'MS': 'Mississippi',\n",
    "    'MT': 'Montana',\n",
    "    'NC': 'North Carolina',\n",
    "    'ND': 'North Dakota',\n",
    "    'NE': 'Nebraska',\n",
    "    'NH': 'New Hampshire',\n",
    "    'NJ': 'New Jersey',\n",
    "    'NM': 'New Mexico',\n",
    "    'NV': 'Nevada',\n",
    "    'NY': 'New York',\n",
    "    'OH': 'Ohio',\n",
    "    'OK': 'Oklahoma',\n",
    "    'OR': 'Oregon',\n",
    "    'PA': 'Pennsylvania',\n",
    "    'PR': 'Puerto Rico',#\n",
    "    'RI': 'Rhode Island',\n",
    "    'SC': 'South Carolina',\n",
    "    'SD': 'South Dakota',\n",
    "    'TN': 'Tennessee',\n",
    "    'TX': 'Texas',\n",
    "    'UT': 'Utah',\n",
    "    'VA': 'Virginia',\n",
    "    'VI': 'Virgin Islands',#\n",
    "    'VT': 'Vermont',\n",
    "    'WA': 'Washington',\n",
    "    'WI': 'Wisconsin',\n",
    "    'WV': 'West Virginia',\n",
    "    'WY': 'Wyoming'\n",
    "}\n",
    "\n",
    "def state_std(x:str):\n",
    "\n",
    "    if x is None:\n",
    "        return \"\"\n",
    "\n",
    "    elif (len(x) == 2) & (x.isalpha()):\n",
    "        return x.upper()\n",
    "    else:\n",
    "        for key, value in states.items():\n",
    "            if x.lower() == value.lower():\n",
    "                return key\n",
    "        return \"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "lead[\"STATE_STD\"] = lead[\"STATE\"].apply(state_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "wa_lead = lead[(lead[\"IS_DELETED\"] == False)& (lead[\"STATE_STD\"] == \"WA\")& (lead[\"STATUS\"]!= \"New\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# task\n",
    "query = \"SELECT * FROM lake.salesforce.task WHERE WHO_ID IN (SELECT ID from lake.salesforce.lead WHERE (lower(STATE) LIKE 'wa%'))\"\n",
    "wa_task = cur.execute(query).fetch_pandas_all().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lead_hist\n",
    "query = \"SELECT * FROM LAKE.SALESFORCE.LEAD_HISTORY\"\n",
    "lead_hist = cur.execute(query).fetch_pandas_all().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "wa_lead_hist = lead_hist[(lead_hist[\"LEAD_ID\"].isin(wa_lead[\"ID\"])) & (lead_hist[\"IS_DELETED\"] == False)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# listing\n",
    "query = \"SELECT * FROM LAKE.SALESFORCE.LISTING_C\"\n",
    "listing = cur.execute(query).fetch_pandas_all().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "wa_lead_listing = listing[listing[\"LEAD_C\"].isin(wa_lead[\"ID\"])]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### rollback data using cutoff date"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### rollback_wa_lead"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "cutoff_date_start = dt.date(2021,7,1)\n",
    "cutoff_date_end = dt.date(2022,1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# leadConvertted, created, leadMerged:  field has ineffective value changes (None to None) so that it's excluded\n",
    "# Owner: Owner can't be found in lead columns\n",
    "# ownerAssignment: need a extra filter to specify DATATYPE ==EntityId\n",
    "\n",
    "# function to standardize the field name\n",
    "def field_std(x:str) -> str:\n",
    "\n",
    "    field_replace_dict = {\"MobilePhone\":\"MOBILE_PHONE\",\n",
    "                    \"LeadSource\":\"LEAD_SOURCE\", \n",
    "                    \"Brokerage1__c\": \"BROKERAGE_1_C\",\n",
    "                    \"ownerAssignment\": \"OWNER_ID\",\n",
    "                    \"HasOptedOutOfEmail\":\"HAS_OPTED_OUT_OF_EMAIL\"}\n",
    "\n",
    "    for key in field_replace_dict.keys():\n",
    "        if x == key:\n",
    "            x = field_replace_dict[key]\n",
    "            \n",
    "    x = x.upper()\n",
    "    x = x.replace(\"__\",\"_\")\n",
    "    \n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rollback function\n",
    "# to rollback the status of the lead status, using the lead_hist, changing the value at the 'lead' dataset\n",
    "\n",
    "# steps:\n",
    "# set the cutoff date: cutoff date start, cutoff date end\n",
    "# forward search the lead_hist, using lead_id and the lead_hist in range cutoff date, find the earlist change of each type of changes, and extract the old_value, replace the value on related columns\n",
    "# return the dataset\n",
    "\n",
    "def rollback_lead(input_lead_df:pd.DataFrame, \n",
    "                    lead_hist_df:pd.DataFrame, \n",
    "                    cutoff_date_start:dt.date, \n",
    "                    cutoff_date_end:dt.date) -> pd.DataFrame:\n",
    "    \n",
    "    #subset the data using lead id and cutoff dates\n",
    "    subset_hist_df = lead_hist_df[(lead_hist_df[\"LEAD_ID\"].isin(input_lead_df[\"ID\"])) & (lead_hist_df[\"CREATED_DATE\"].dt.date >= cutoff_date_start) & (lead_hist_df[\"CREATED_DATE\"].dt.date <= cutoff_date_end)]\n",
    "\n",
    "    # drop rows that contains fields which does not refer back to lead dataset\n",
    "    filter_values = [\"leadConvertted\",\"created\",\"leadMerged\",\"Owner\"]\n",
    "    subset_hist_df = subset_hist_df[~subset_hist_df[\"FIELD\"].isin(filter_values)]\n",
    "    \n",
    "    # ownerAssignment: need a extra filter to drop DATATYPE ==EntityId\n",
    "    subset_hist_df = subset_hist_df[~(((subset_hist_df[\"FIELD\"] == \"Owner\") | (subset_hist_df[\"FIELD\"] == \"ownerAssignment\") )& (subset_hist_df[\"DATA_TYPE\"] == \"EntityId\"))]\n",
    "\n",
    "    # apply the field standardization function\n",
    "    subset_hist_df[\"FIELD_STD\"] = subset_hist_df[\"FIELD\"].apply(field_std)\n",
    "\n",
    "    # create a dataframe for output\n",
    "    output_df = pd.DataFrame()\n",
    "\n",
    "    # need to check cases with same fields\n",
    "    for id in input_lead_df[\"ID\"]:\n",
    "        # extract the lead hist of the certain id\n",
    "        id_subset = subset_hist_df[subset_hist_df[\"LEAD_ID\"] == id]\n",
    "        # filter only the first changes, by kind of fields\n",
    "        id_subset = id_subset.loc[id_subset.groupby(\"FIELD_STD\")[\"CREATED_DATE\"].idxmin()]\n",
    "        # create the dictionary to replace\n",
    "        replace_dict = dict(zip(id_subset[\"FIELD_STD\"],id_subset[\"OLD_VALUE\"]))\n",
    "        # pullout the id realted row for replacement\n",
    "        lead_id_row = input_lead_df[input_lead_df[\"ID\"] == id]\n",
    "        # extract id index\n",
    "        id_idx = lead_id_row.index\n",
    "        # convert id row to dictonary\n",
    "        lead_id_dict = lead_id_row.to_dict(\"index\")[id_idx.values[0]]\n",
    "        # use replace dict to update\n",
    "        lead_id_dict.update(replace_dict)\n",
    "        # transform back to dataframe and append to output dataframe\n",
    "        output_df = pd.concat([output_df, pd.DataFrame(lead_id_dict, index = id_idx)])\n",
    "\n",
    "    return output_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "cutoff_wa_lead = rollback_lead(wa_lead,wa_lead_hist,cutoff_date_start,cutoff_date_end)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### cutoff_wa_task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('O')"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wa_task[\"ACTIVITY_DATE\"].dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "cutoff_wa_task= wa_task[pd.to_datetime(wa_task[\"ACTIVITY_DATE\"]).dt.date < cutoff_date_end]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### cutoff_wa_lead_hist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "cutoff_wa_lead_hist = wa_lead_hist[wa_lead_hist[\"CREATED_DATE\"].dt.date < cutoff_date_end]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### cutoff_wa_lead_listing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "cutoff_wa_lead_listing = wa_lead_listing[pd.to_datetime(wa_lead_listing[\"ACTIVE_DATE_C\"]).dt.date < cutoff_date_end]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### output the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cutoff_wa_lead.to_csv(\"../data/cutoff_wa_lead.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cutoff_wa_task.to_csv(\"../data/cutoff_wa_task.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cutoff_wa_lead_hist.to_csv(\"../data/cutoff_wa_lead_hist.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cutoff_wa_lead_listing.to_csv(\"../data/cutoff_wa_lead_listing.csv\")"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "3e67353882427c901042c1d493e3dd4483568013277e790881b084b86e9e0511"
  },
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
